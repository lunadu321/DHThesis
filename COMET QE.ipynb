{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63361108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from comet import download_model, load_from_checkpoint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "344b7854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_translations(source_file, translated_file, batch_size=8):\n",
    "    # Load the pretrained Comet model for reference-free evaluation\n",
    "    model_path = download_model(\"wmt20-comet-qe-da\")\n",
    "    model = load_from_checkpoint(model_path)\n",
    "\n",
    "    # Read the source and translated texts from files\n",
    "    with open(source_file, 'r', encoding='utf-8') as f:\n",
    "        source_sentences = f.readlines()\n",
    "\n",
    "    with open(translated_file, 'r', encoding='utf-8') as f:\n",
    "        translated_sentences = f.readlines()\n",
    "\n",
    "    # Ensure both files have the same number of lines\n",
    "    assert len(source_sentences) == len(translated_sentences), \"Source and translation files must have the same number of lines\"\n",
    "\n",
    "    # Prepare the data as a list of dictionaries\n",
    "    data = [{\"src\": src.strip(), \"mt\": mt.strip()} for src, mt in zip(source_sentences, translated_sentences)]\n",
    "\n",
    "    # Evaluate the translations in batches\n",
    "    scores = []\n",
    "\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batch = data[i:i + batch_size]\n",
    "        results = model.predict(batch, batch_size=batch_size, gpus=1)\n",
    "        scores.extend(results[\"scores\"])\n",
    "    \n",
    "    # Calculate the average score\n",
    "    average_score = sum(scores) / len(scores)\n",
    "\n",
    "    # Print the scores\n",
    "    for idx, score in enumerate(scores):\n",
    "        print(f\"Sentence {idx + 1}: {score}\")\n",
    "    \n",
    "    print(f\"\\nAverage Score: {average_score}\")\n",
    "\n",
    "    return scores, average_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eab94d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wmt20-comet-qe-da is already in cache.\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.3.5 to v2.2.5. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint C:\\Users\\dudud\\.cache\\torch\\unbabel_comet\\wmt20-comet-qe-da\\checkpoints\\model.ckpt`\n",
      "Encoder model frozen.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.34s/it]\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.27s/it]\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.66s/it]\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.43s/it]\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|███████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: 0.765214741230011\n",
      "Sentence 2: 0.7160375714302063\n",
      "Sentence 3: 0.2187006175518036\n",
      "Sentence 4: 0.27371370792388916\n",
      "Sentence 5: 0.26585742831230164\n",
      "Sentence 6: 0.0001610626932233572\n",
      "Sentence 7: 0.27133411169052124\n",
      "Sentence 8: 0.013192736543715\n",
      "Sentence 9: 0.5712112784385681\n",
      "Sentence 10: 5.73097713640891e-05\n",
      "Sentence 11: 0.09418582171201706\n",
      "Sentence 12: 0.6893768310546875\n",
      "Sentence 13: 0.3468148112297058\n",
      "Sentence 14: 0.1076871007680893\n",
      "Sentence 15: 0.311440110206604\n",
      "Sentence 16: 9.204715024679899e-05\n",
      "Sentence 17: 0.00027742513339035213\n",
      "Sentence 18: 0.16297395527362823\n",
      "Sentence 19: 4.286716284696013e-05\n",
      "Sentence 20: 4.112221722607501e-05\n",
      "Sentence 21: 0.7198349237442017\n",
      "Sentence 22: 4.124750921619125e-05\n",
      "Sentence 23: 6.345268775476143e-05\n",
      "Sentence 24: 0.13707566261291504\n",
      "Sentence 25: 0.39426344633102417\n",
      "Sentence 26: 0.2757658362388611\n",
      "Sentence 27: 0.01686958596110344\n",
      "Sentence 28: 0.7178642153739929\n",
      "Sentence 29: 4.189591345493682e-05\n",
      "Sentence 30: 7.614305650349706e-05\n",
      "Sentence 31: 0.3669449985027313\n",
      "Sentence 32: 0.06321132928133011\n",
      "Sentence 33: 0.1932300627231598\n",
      "Sentence 34: 0.07705044746398926\n",
      "Sentence 35: 0.359455943107605\n",
      "Sentence 36: 4.157671355642378e-05\n",
      "Sentence 37: 4.2292602302040905e-05\n",
      "Sentence 38: 0.00010595617641229182\n",
      "Sentence 39: 0.09835142642259598\n",
      "Sentence 40: 0.1667388379573822\n",
      "Sentence 41: 0.00010357304563513026\n",
      "Sentence 42: 4.0521899791201577e-05\n",
      "Sentence 43: 4.204416472930461e-05\n",
      "Sentence 44: 0.08635246008634567\n",
      "Sentence 45: 0.00027081798180006444\n",
      "Sentence 46: 0.24106940627098083\n",
      "Sentence 47: 0.4574742317199707\n",
      "Sentence 48: 0.10722503066062927\n",
      "\n",
      "Average Score: 0.19350125049383374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "source_file = \"C:/Users/dudud/Desktop/ss.txt\"\n",
    "translated_file = \"C:/Users/dudud/Desktop/fewshot.txt\"\n",
    "scores, average_score = evaluate_translations(source_file, translated_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce8fac9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.765214741230011, 0.7160375714302063, 0.2187006175518036, 0.27371370792388916, 0.26585742831230164, 0.0001610626932233572, 0.27133411169052124, 0.013192736543715, 0.5712112784385681, 5.73097713640891e-05, 0.09418582171201706, 0.6893768310546875, 0.3468148112297058, 0.1076871007680893, 0.311440110206604, 9.204715024679899e-05, 0.00027742513339035213, 0.16297395527362823, 4.286716284696013e-05, 4.112221722607501e-05, 0.7198349237442017, 4.124750921619125e-05, 6.345268775476143e-05, 0.13707566261291504, 0.39426344633102417, 0.2757658362388611, 0.01686958596110344, 0.7178642153739929, 4.189591345493682e-05, 7.614305650349706e-05, 0.3669449985027313, 0.06321132928133011, 0.1932300627231598, 0.07705044746398926, 0.359455943107605, 4.157671355642378e-05, 4.2292602302040905e-05, 0.00010595617641229182, 0.09835142642259598, 0.1667388379573822, 0.00010357304563513026, 4.0521899791201577e-05, 4.204416472930461e-05, 0.08635246008634567, 0.00027081798180006444, 0.24106940627098083, 0.4574742317199707, 0.10722503066062927]\n"
     ]
    }
   ],
   "source": [
    "print (scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3d1f84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
